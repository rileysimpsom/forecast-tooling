# This is the all-in-one file that replaces the Astro CLI
# It will start, configure, and network all 6 services.

x-airflow-common:
  &airflow-common
  # This tells Docker to build the image from the root 'Dockerfile'
  build: .
  image: open-source-sales-forecasting:latest
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__LOAD_EXAMPLES=false
    # --- Pass all credentials and endpoints to Airflow ---
    - AIRFLOW__MLFLOW__TRACKING_URI=http://mlflow:5001
    - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    - AWS_ACCESS_KEY_ID=minioadmin
    - AWS_SECRET_ACCESS_KEY=minioadmin
    - AWS_DEFAULT_REGION=us-east-1
  volumes:
    # Mount your local code folders into the running container
    - ./dags:/opt/airflow/dags
    - ./include:/opt/airflow/include
    - ./logs:/opt/airflow/logs
  # All services that use this (webserver, scheduler)
  # will wait for postgres AND airflow-init to be done.
  depends_on:
    - postgres
    - airflow-init
  networks:
    - airflow-net

services:
  # ------------------------------------------------------------------
  # AIRFLOW SERVICES (Postgres DB, Init, Webserver, Scheduler)
  # ------------------------------------------------------------------
  postgres:
    image: postgres:14
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - airflow-db-volume:/var/lib/postgresql/data
    networks:
      - airflow-net
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    # --- THIS IS THE FIX ---
    # We OVERRIDE the depends_on from x-airflow-common
    # The init service should ONLY wait for postgres.
    # It cannot wait for itself.
    depends_on:
      - postgres
    entrypoint: /bin/bash
    command:
      - -c
      - |
        # Wait for Postgres to be ready
        until pg_isready -h postgres -p 5432 -U airflow; do
          echo "Waiting for PostgreSQL...";
          sleep 2;
        done;
        # Init the Airflow DB
        airflow db init;
        # Create admin user (username: admin, password: admin)
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true;
        # Create the MinIO connection Airflow will use
        airflow connections add 'minio_default' \
          --conn-type 'aws' \
          --conn-login 'minioadmin' \
          --conn-password 'minioadmin' \
          --conn-extra '{"host": "http://minio:9000", "region_name": "us-east-1"}' || true;
    # This service runs once and then exits.
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: airflow webserver
    ports:
      - "8080:8080" # Airflow UI
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: airflow scheduler
    restart: always

  # ------------------------------------------------------------------
  # ML & APP SERVICES (MinIO, MLflow, Streamlit)
  # ------------------------------------------------------------------
  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000" # MinIO API
      - "9001:9001" # MinIO UI
    volumes:
      - minio-data-volume:/data
    networks:
      - airflow-net

  create-minio-buckets:
    image: minio/mc
    container_name: create-minio-buckets
    depends_on:
      - minio
    entrypoint: /bin/sh
    command: >
      -c "
      echo 'Waiting for MinIO...';
      until /usr/bin/mc config host add minio_local http://minio:9000 minioadmin minioadmin; do sleep 1; done;
      echo 'Creating buckets...';
      /usr/bin/mc mb minio_local/mlflow || true;
      /usr/bin/mc mb minio_local/airflow-logs || true;
      echo 'Buckets created.';
      "
    networks:
      - airflow-net
    restart: "no"

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.12.1
    container_name: mlflow
    environment:
      # Use Postgres as the backend store
      - MLFLOW_POSTGRES_HOST=postgres
      - MLFLOW_POSTGRES_PORT=5432
      - MLFLOW_POSTGRES_USER=airflow
      - MLFLOW_POSTGRES_PASSWORD=airflow
      - MLFLOW_POSTGRES_DB=airflow
      # Use MinIO as the artifact store
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_DEFAULT_REGION=us-east-1
    # Command to use port 5001 (from your original ui/Dockerfile)
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5001 
      --backend-store-uri postgresql://${MLFLOW_POSTGRES_USER}:${MLFLOW_POSTGRES_PASSWORD}@${MLFLOW_POSTGRES_HOST}:${MLFLOW_POSTGRES_PORT}/${MLFLOW_POSTGRES_DB}
      --default-artifact-root s3://mlflow/
    ports:
      - "5001:5001" # MLflow UI
    depends_on:
      - postgres
      - create-minio-buckets
    networks:
      - airflow-net
    restart: always

  streamlit:
    build:
      context: ./ui # Build from your 'ui' folder
      dockerfile: Dockerfile
    container_name: streamlit
    environment:
      # --- Pass all credentials and endpoints to Streamlit ---
      - MLFLOW_TRACKING_URI=http://mlflow:5001
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_DEFAULT_REGION=us-east-1
    ports:
      - "8501:8501" # Streamlit UI
    volumes:
      - ./ui:/app
    depends_on:
      - mlflow
    networks:
      - airflow-net
    restart: always

volumes:
  airflow-db-volume:
  minio-data-volume:

networks:
  airflow-net:
    driver: bridge